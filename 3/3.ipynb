{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация гиперпараметров \n",
    "     1. С помощью [optuna]() взять пример, аналогичный третьему туториалу документации, используя sklearn и с другим датасетом, выбрать другие  алгоритмы классификации и клстеризации не из туториала  и визуализировать графики для полученного процесса\n",
    "        1. В качестве других моделей подойдут любые алгоритмы классификации и регрессии из sklearn которые не использовались в туториале\n",
    "     2. Использовать 2 разных семплера и прунера\n",
    "     3. При процессе оптимизации гиперпараметров использовать общую память через postgreSQL\n",
    "     4. В качестве отчёта выступают: исходный код, инструкция запуска реляционной БД. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import optuna\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    wine = sklearn.datasets.load_wine()\n",
    "    X, y = wine.data, wine.target\n",
    "    X_train, X_valid, y_train, y_valid = sklearn.model_selection.train_test_split(\n",
    "        X, y, test_size=0.25, random_state=0\n",
    "    )\n",
    "    classes = list(set(y))\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "    model_name = trial.suggest_categorical(\"model\", [\"MultinomialNB\", \"MLPClassifier\"])\n",
    "\n",
    "    if model_name == \"MultinomialNB\":\n",
    "        alpha = trial.suggest_float(\"alpha\", 1e-5, 1e1, log=True)\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "\n",
    "\n",
    "        for step in range(100): \n",
    "            clf.partial_fit(X_train, y_train, classes=classes)\n",
    "            intermediate_value = 1.0 - clf.score(X_valid, y_valid)\n",
    "            trial.report(intermediate_value, step)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    else: \n",
    "        hidden_layer_sizes = trial.suggest_int(\"hidden_layer_sizes\", 10, 100, log=True)\n",
    "        activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"logistic\"])\n",
    "        solver = trial.suggest_categorical(\"solver\", [\"adam\", \"sgd\"])\n",
    "        alpha_mlp = trial.suggest_float(\"alpha_mlp\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "        clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, alpha=alpha_mlp, random_state=0, max_iter=500) # Увеличиваем max_iter\n",
    "        for step in range(100):\n",
    "            clf.partial_fit(X_train_scaled, y_train, classes=classes)\n",
    "            intermediate_value = 1.0 - clf.score(X_valid_scaled, y_valid)\n",
    "            trial.report(intermediate_value, step)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "\n",
    "    return 1.0 - clf.score(X_valid_scaled if model_name == \"MLPClassifier\" else X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Два разных семплера\n",
    "sampler1 = optuna.samplers.TPESampler()\n",
    "sampler2 = optuna.samplers.RandomSampler()\n",
    "\n",
    "# Два разных прунера\n",
    "pruner1 = optuna.pruners.HyperbandPruner()\n",
    "pruner2 = optuna.pruners.MedianPruner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening on http://127.0.0.1:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:26] \"GET / HTTP/1.1\" 302 0\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:26] \"GET /dashboard HTTP/1.1\" 200 4145\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:26] \"GET /static/bundle.js HTTP/1.1\" 200 4158971\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:27] \"GET /apple-touch-icon-precomposed.png HTTP/1.1\" 404 790\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:27] \"GET /apple-touch-icon.png HTTP/1.1\" 404 766\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:27] \"GET /favicon.ico HTTP/1.1\" 200 7670\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:27] \"GET /api/studies HTTP/1.1\" 200 323\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:29] \"GET /api/meta HTTP/1.1\" 200 63\n",
      "/Users/aleksandralekseev/Desktop/karpov_DA/DA_python/venv/lib/python3.9/site-packages/optuna_dashboard/_importance.py:75: ExperimentalWarning: PedAnovaImportanceEvaluator is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  return get_param_importances(study, target=target, evaluator=PedAnovaImportanceEvaluator())\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:29] \"GET /api/studies/1?after=0 HTTP/1.1\" 200 90609\n",
      "/Users/aleksandralekseev/Desktop/karpov_DA/DA_python/venv/lib/python3.9/site-packages/optuna/importance/_ped_anova/evaluator.py:150: UserWarning: PedAnovaImportanceEvaluator computes the importances of params to achieve low `target` values. If this is not what you want, please modify target, e.g., by multiplying the output by -1.\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:29] \"GET /api/studies/1/param_importances HTTP/1.1\" 200 106\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:30] \"GET /api/studies HTTP/1.1\" 200 323\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:32] \"GET /api/meta HTTP/1.1\" 200 63\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:32] \"GET /api/studies/2?after=0 HTTP/1.1\" 200 84717\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:32] \"GET /api/studies/2/param_importances HTTP/1.1\" 200 106\n",
      "127.0.0.1 - - [23/Dec/2024 15:34:33] \"GET /api/studies HTTP/1.1\" 200 323\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandralekseev/Desktop/karpov_DA/DA_python/venv/bin/optuna-dashboard\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/aleksandralekseev/Desktop/karpov_DA/DA_python/venv/lib/python3.9/site-packages/optuna_dashboard/_cli.py\", line 140, in main\n",
      "    run_wsgiref(app, args.host, args.port, args.quiet)\n",
      "  File \"/Users/aleksandralekseev/Desktop/karpov_DA/DA_python/venv/lib/python3.9/site-packages/optuna_dashboard/_cli.py\", line 44, in run_wsgiref\n",
      "    httpd.serve_forever()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!optuna-dashboard postgresql://aleksandralekseev:@localhost/optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:16,381] A new study created in RDB with name: no-name-2234e946-be70-41b1-8bfc-8448949ab8fb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in RDB with name: no-name-2234e946-be70-41b1-8bfc-8448949ab8fb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:17,231] Trial 0 finished with value: 0.5333333333333333 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 44, 'activation': 'logistic', 'solver': 'sgd', 'alpha_mlp': 3.1979038429721285e-05}. Best is trial 0 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.5333333333333333 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 44, 'activation': 'logistic', 'solver': 'sgd', 'alpha_mlp': 3.1979038429721285e-05}. Best is trial 0 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:18,083] Trial 1 finished with value: 0.48888888888888893 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 16, 'activation': 'logistic', 'solver': 'adam', 'alpha_mlp': 0.0027751476971407006}. Best is trial 1 with value: 0.48888888888888893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.48888888888888893 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 16, 'activation': 'logistic', 'solver': 'adam', 'alpha_mlp': 0.0027751476971407006}. Best is trial 1 with value: 0.48888888888888893.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:18,929] Trial 2 finished with value: 0.11111111111111116 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 15, 'activation': 'relu', 'solver': 'adam', 'alpha_mlp': 0.07559032722222556}. Best is trial 2 with value: 0.11111111111111116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.11111111111111116 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 15, 'activation': 'relu', 'solver': 'adam', 'alpha_mlp': 0.07559032722222556}. Best is trial 2 with value: 0.11111111111111116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:19,617] Trial 3 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.36967780669495054}. Best is trial 3 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.36967780669495054}. Best is trial 3 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:20,489] Trial 4 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 1.521422788661296e-05}. Best is trial 3 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 1.521422788661296e-05}. Best is trial 3 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:21,229] Trial 5 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.7313988343474822}. Best is trial 3 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.7313988343474822}. Best is trial 3 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:21,316] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:21,401] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:22,185] Trial 8 finished with value: 0.0444444444444444 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 96, 'activation': 'tanh', 'solver': 'adam', 'alpha_mlp': 0.0016670263901089706}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 finished with value: 0.0444444444444444 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 96, 'activation': 'tanh', 'solver': 'adam', 'alpha_mlp': 0.0016670263901089706}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:22,303] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:23,013] Trial 10 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.00016891035464578554}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.00016891035464578554}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:23,086] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:24,016] Trial 12 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.029783755414486874}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.029783755414486874}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:24,822] Trial 13 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.03285996815142248}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.03285996815142248}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:24,913] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:25,710] Trial 15 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.4073977101547135}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.4073977101547135}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:26,326] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:27,045] Trial 17 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.0007967443165527248}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.0007967443165527248}. Best is trial 8 with value: 0.0444444444444444.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:27,124] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:24:27,185] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 pruned. \n",
      "Study 1 best params: {'model': 'MLPClassifier', 'hidden_layer_sizes': 96, 'activation': 'tanh', 'solver': 'adam', 'alpha_mlp': 0.0016670263901089706}, best value: 0.0444444444444444\n"
     ]
    }
   ],
   "source": [
    "# Оптимизация с sampler1 и pruner1\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)])\n",
    "study1 = optuna.create_study(direction=\"minimize\", sampler=sampler1, pruner=pruner1, storage='postgresql://aleksandralekseev:@localhost/optuna')\n",
    "study1.optimize(objective, n_trials=20)\n",
    "print(f\"Study 1 best params: {study1.best_params}, best value: {study1.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:39,956] A new study created in RDB with name: no-name-e176d08d-c398-4af8-ab4e-1cec404541b0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in RDB with name: no-name-e176d08d-c398-4af8-ab4e-1cec404541b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:40,933] Trial 0 finished with value: 0.06666666666666665 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 75, 'activation': 'tanh', 'solver': 'adam', 'alpha_mlp': 0.0010173422709758202}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.06666666666666665 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 75, 'activation': 'tanh', 'solver': 'adam', 'alpha_mlp': 0.0010173422709758202}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:41,772] Trial 1 finished with value: 0.0888888888888889 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 82, 'activation': 'tanh', 'solver': 'sgd', 'alpha_mlp': 0.05427293411539595}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.0888888888888889 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 82, 'activation': 'tanh', 'solver': 'sgd', 'alpha_mlp': 0.05427293411539595}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:42,506] Trial 2 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 5.346029826501508}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 5.346029826501508}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:43,378] Trial 3 finished with value: 0.5333333333333333 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 20, 'activation': 'logistic', 'solver': 'sgd', 'alpha_mlp': 0.00012342603867367073}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 0.5333333333333333 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 20, 'activation': 'logistic', 'solver': 'sgd', 'alpha_mlp': 0.00012342603867367073}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:44,304] Trial 4 finished with value: 0.11111111111111116 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 18, 'activation': 'tanh', 'solver': 'adam', 'alpha_mlp': 7.656582044515186e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.11111111111111116 and parameters: {'model': 'MLPClassifier', 'hidden_layer_sizes': 18, 'activation': 'tanh', 'solver': 'adam', 'alpha_mlp': 7.656582044515186e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:44,354] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:44,412] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:44,461] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:45,474] Trial 8 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 1.1128849383028156e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 1.1128849383028156e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:46,297] Trial 9 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 6.437216284137439e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 6.437216284137439e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:47,093] Trial 10 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.23377167852312342}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.23377167852312342}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:48,384] Trial 11 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.053758879160674636}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 0.053758879160674636}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:48,431] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:48,472] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:48,510] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:49,377] Trial 15 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 1.4688463163318888e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 1.4688463163318888e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:49,436] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:49,489] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:50,403] Trial 18 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 4.20011053666392e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 finished with value: 0.06666666666666665 and parameters: {'model': 'MultinomialNB', 'alpha': 4.20011053666392e-05}. Best is trial 0 with value: 0.06666666666666665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 15:30:50,480] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 pruned. \n",
      "Study 2 best params: {'model': 'MLPClassifier', 'hidden_layer_sizes': 75, 'activation': 'tanh', 'solver': 'adam', 'alpha_mlp': 0.0010173422709758202}, best value: 0.06666666666666665\n"
     ]
    }
   ],
   "source": [
    "# Оптимизация с sampler2 и pruner2\n",
    "study2 = optuna.create_study(direction=\"minimize\", sampler=sampler2, pruner=pruner2, storage='postgresql://aleksandralekseev:@localhost/optuna')\n",
    "study2.optimize(objective, n_trials=20)\n",
    "print(f\"Study 2 best params: {study2.best_params}, best value: {study2.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
